[[{"l":"The Green Alliance"},{"l":"Who We Are","p":["We are the vision subteam from FRC team 3656, the Dexter Dreadbots. Over time, new members will replace our old writers, and we plan on keeping this wiki up to date for as long as we still exist. We are always open to pull requests on our github in case you would like to add an article. More information on contributing can be found there."]},{"l":"Our Mission","p":["Our mission is to provide beginner-friendly, easy-to-implement documentation and articles to help you implement hand written vision into your FIRST team's robot."]},{"l":"What You Need","p":["To get started, we reccomend a webcam (anything around 720p or above will do), and a computer with python 3, pip, and an IDE of your choice to write it in. We recommend using VSCode if you are a beginner; it has a great plugin for python and a large community around it."]}],[{"l":"Math","p":["Without math, computer vision wouldn't exist. Though it may not be used to directly process the images, it forms the heart of the processing pipeline. It comes in many shapes and sizes, depending on the use case and efficiency of the operations; for instance, trigonometry is useful for mid-level processes, but basic geometry is sufficient for a lot of use cases (described briefly in Introduction to Pinholes). Eventually, we'll have articles on everything from simple geometry to linear algebra, but for now we'll start with beginning trigonometry."]}],[{"l":"Linear Algebra","p":["Linear Algebra is an important tool that we use to help find the position of the robot on the field."]},{"l":"Vectors","p":["Vectors are used to represent a direction and magnitude. Usually they are graphically denoted by an arrow: the length represents the magnitude of the arrow and the starting and ending points represent the direction. On paper they are represent with square brackets [] with numbers vertically stacked. The top represents the x direction, below that is the y, and in 3 dimensions their will be z below that.","The above 2d vector represents an arrow with the x component being 10 units and the y component being two units, so you can imagine this as an arrow going from the point (0, 0) to the point (10, 2). In the context of robots, these vectors usually represent the position of something. For example, vectors are often used to represent where an april tag is from the camera."]},{"l":"Matrices","p":["In essence, matrices are a way to hold multiple pieces of information in a single entity.","Above is a two by two matrix. Graphically, however, representing them is a bit more complex. We generally think of matrices as transformations of the coordinate grid. Lets say we start with a vector","on the grid, but then we want to transform this vector using a matrix.","Applying this transformation, we get the x component, a, multilying the first column, and the y component, b, multiplying the second component:","and","combining these into a single vector we get our result vector:","This multi-step proccess is more commonly described as matrix multiplication. However, matrix multiplication isn't as simple as scalar multiplication, so you can't just multiply the corresponding components. I won't get into the details of matrx multiplication, but for more info on linear algebra and to get a much better visual representation of what has been explained in this article, I suggest watching this video series on youtube."]}],[{"l":"Trigonometry","p":["Having a basic understanding of trigonometry is essential to understanding how to take data from an image and projecting it back into the real world. Trigonometry is the mathematics behind triangles, and mostly it gives us a few operations we can use on angles or side lengths to solve for the exact dimensions of a triangle."]},{"l":"SOH CAH TOA","p":["The three basic trig functions are \\sin, \\cos, and \\tan. Given the triangle:","We can define these functions as:","There are also inverse functions for these, so that you can determine the angle from the side lengths. These can be written in one of two ways: putting\\text{arc} in front, or by putting a ^{-1} right after the function, such as:","So as not to get \\sin^{-1} x confused with (\\sin x)^{-1}, there are another 3 functions that represent the reciprocals of the first three:","all of which can also be inverted by the same methods as above."]}],[{"l":"Cameras","p":["Cameras are the foundation of computer vision; without them, we wouldn't have images to process in the first place. Needless to say, at least a basic understanding is essential for working with vision code; thankfully, they're not as complicated as it seems."]},{"l":"Establishing the Type","p":["There are a couple of types of cameras, the main two that we'll focus on are fisheyes and pinholes. Generally, if you're thinking of a camera, it's a pinhole. Fisheyes are a lot more complicated, and involve a heap of extra work before they can be processed with computer vision. For most computer vision purposes, especially in FRC robotics, pinhole cameras will be sufficient, and so that's what our articles will go in depth on."]}],[{"l":"Introduction to Pinholes","p":["Pinhole cameras let light converge into a tiny hole (a pinhole!) and then diverge on the other side onto an image plane. In old cameras, this plane was the film. In digital cameras, it's a little more complicated, but the premise remains the same. This allows us to create this lovely diagram that forms the core of our vision systems:"]},{"l":"Interpreting the Triangles","p":["Ok, so what the heck does that mean? This is a vertical side-view of a camera, where the intersection of the two dashed lines is the pinhole of the camera. The section of the horizontal dashed line on the camera's side (labelled as f) is the distance between the pinhole and the image plane.","The pinhole of the camera, where light converges, is known as a focal point, and the distance between it and the image plane is known as the focal length!","The image plane's height is marked as py, indicating p ixel y-axis length, and it represents a single column of pixels in the captured images.","This diagram doesn't have to be a vertical side-view, though; we can simply rename the py line to px and it is now a horizontal side-view, where the px line represents a single row of pixels in the captured image.","Don't get confused — we can't actually just say that py is the same as px; it's just a simple way to show that the camera's horizontal side-view shares proportionality with it's vertical side-view. When we put actual math into it, you'll have to consider the py and px sides separately."]},{"l":"Applications of the Triangles","p":["These triangles allow us to approximate the location of a target, provided that we can detect it with computer vision, and that we have some knowns about it. Let's draw in a few more things on the diagram:","That was a lot. Let's take it down part by part: the point labelled target is whatever we're targeting, possibly a piece of retroreflective tape on the wall? target (in image) indicates the position of the pixel that shows the target in the camera. You'll notice that it's upside down on the diagram; this is a side-effect of the pinhole structure.","The image gets flipped right-side up before it ever passes through to the code. However, drawing it like this makes it more intuitive to look at. Just remember that the py line is upside down!","Next, the segment marked h is the height of the target, relative to the camera's height (the distance vertically from the camera to the target). The segment marked d is the distance of the target from the camera laterally. The segment marked ph is the distance, in pixels, from the centre of the image to the pixel that the target appears on in the image.","So how do we use this diagram? Well, we can use the principle of similar triangles to solve for various unknowns: the triangle on the inside of the camera is proportional to that outside the camera. Here's what that looks like in an equation:","Since p_h and f are known ( p_h because it's in the image and f because it's constant and intrinsic to the camera), we can solve for either d or h as long as we know the other one. For a real-world application, if we know that the retroreflective tape is 8 feet off the ground, we can solve for how far away it is from the camera. For example's sake, let's say that it's pixel height is 200 px, and the camera's focal length is 678 px. We can solve for d by cross-multiplying:","It's as easy as that! No complicated trigonometry or linear algebra. Things get quite a bit harder when you don't know either distance or height, or if your target is more complex than a simple piece of retro tape or apriltag that can be represented by a single point."]}],[{"i":"#","p":["This section is a stub! Look for more in a future update."]},{"l":"Raspberry Pis","p":["The computer that most people use for computer vision in FRC is the raspberry pi, due to their ease of use, compact size, and relatively low price tag. Even though they may not have the greatest of processing power, they do well enough to be able to run computer vision for a robot! When setting up a pi, most will install the default Raspberry PI operating system, a special flavour of Debian optimised for the pi."]}],[{"i":"#","p":["This section is a stub! Look out for more in a future update."]},{"i":"what-is-opencv","l":"What is OpenCV?","p":["OpenCV (Computer Vision) is a programming library that can help us achieve our goals when it comes to computer vision. As the name says, OpenCV is fully open source, and it handles much of the base level work with vision, including various aspects of image processing."]},{"l":"How to Use","p":["OpenCV has great documentation on all of its various functions and features, however, we obviously can't cover all of them in these docs. We will try to cover all of the important snippets when we need them, but if you want to go more in-depth, you can find their documentation in the OpenCV docs.","There is no need to go looking too far into the docs, as we will show how to program any concepts we mention, but don't be afraid to look."]}],[{"l":"Implementation","p":["Now that you've seen some of the concepts of computer vision, it's time to implement them. We use Python 3, as our main programming language, and so most of the examples here will use that as well. Examples in other languages are coming soon!"]}],[{"l":"Driver Camera","p":["The simplest useful kind of vision program is one which just pushes an image to the driver station. In previous years, we would use the WPILib CameraServer, but due to recent updates to network tables code, as well as some issues with pip, the python package manager, we have moved to doing a simple mjpeg stream(which is exactly what camera server was under the hood) using mjpeg-streamer. To install, simply run pip install mjpeg-streamer in a virtual environment, or pip install mjpeg-streamer --break-system-packages(it sounds scary, but it's actually not!). You'll also need opencv-python or opencv-python-headless. Then, the minimally functional program is:","That's a lot, so let's go chunk by chunk:","This creates a VideoCapture object around camera 0, but you should swap out 0 for whatever the camera id is. Finding this is notoriously difficult, but if all else fails, try -1, which should use the last available camera.","This creates a mjpeg stream with name stream_name and a specific size. You should change the size parameter to accurately represent the width and height of the images your camera takes in form (width, height).","This creates an mjpeg server hosted locally ( 127.0.0.1 is an ip address that refers to the current computer) on port 1181, accessible from a browser by xx.xx.xx.xx:1181, replacing the x s with the pi's IP address on the network. The stream is then added to the server, and then server is started.","Forever, this reads a frame from the camera and then pushes it through the stream.","If you run this program and then navigate to xx.xx.xx.xx:1181, as above, you should be able to see the stream! To stop it, you'll have to press ^C(control-C), potentially twice, to actually stop the program. This will cause it to get a little mad, so to fix that, we can do this instead:","The notable differences are wrapping the code in the function main, and then the if statement at the bottom: __name__ will be set to __main__ if the program is being run from the shell, but not if the file has been import ed into another python file; it's just generally a good practice. The try/ except KeyboardInterrupt will run main(), which loops until it receives an exception, including a KeyboardInterrupt event (you pressing ^C). By except ing and pass ing, we can \"gracefully\" catch the KeyboardInterrupt and end the program from there.","Congratulations, you just wrote your first vision program! Next, we'll look into detecting AprilTags, the new standard for marking FIRST fields."]}],[{"i":"about---the-meta-section","l":"About - the Meta Section","p":["This section holds information pertaining to the website specifically; notably the Contributors and Roadmap pages, as well as information on contributing to the site yourself."]}],[{"l":"Roadmap","p":["April 15, 2024: Preview of the Crescendo update (Launch/pre-ɣ pre-v1.0.0)","May 1, 2024: Crescendo update (Launch/ɣ v1.0.0)","Linear Algebra","Apriltag articles","Raspberry pi instructions","May 1, 2025: ??? update (δ v2.0.0)"]}],[{"l":"Contributors","p":["Bolded names are project leaders for that year.","2022 (pre-launch): Cole Scheller, Calvin C Ophoff, Josh Fernandez, Rose Dray","2023 (pre-launch): Calvin C Ophoff, Rose Dray","2024 (launch): Calvin C Ophoff, Luke Baur, Fynn Nielsen, Arman Buyukbozkirlii"]}],[{"i":"launch--pre-ɣ","l":"Launch / pre-ɣ","p":["This version of the site is Launch/pre-ɣ (pre-v1.0.0), released during the FIRST in Show season and the Crescendo game (2024)."]}]]